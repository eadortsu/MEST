{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KS6N9_3r8pFf"
   },
   "source": [
    "# MEST DAY 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hzsOrc2f8rzV"
   },
   "source": [
    "## Morning Session\n",
    "\n",
    "### Activation Functions\n",
    "Recall that $\\hat{y} = w.x$\n",
    "* Sigmoid $\\sigma(\\hat{y}) = \\frac{1}{1 + e^{-\\hat{y}}} $\n",
    "* Hyperbolic Tangent\n",
    "* Rectified Linear Unit\n",
    "\n",
    "### Playground\n",
    "* Gradient Descent\n",
    "* Learning Rates\n",
    "\n",
    "* http://playground.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "colab_type": "code",
    "id": "ozT60RL_Buza",
    "outputId": "a9bcecd0-b5a2-4894-8762-da0d25f1fc76"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.0.0-beta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NztJCZiCAxYx"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "xFY0nyT9BqsL",
    "outputId": "25953f50-6037-42a9-e800-7ccbb07a3c39"
   },
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "2bkgHniOA0Kk",
    "outputId": "457c5c4b-56ed-4a42-8a85-7b8b0f66aa94"
   },
   "outputs": [],
   "source": [
    "a = np.random.normal(0, 1, (5, 2))\n",
    "b = np.random.normal(0, 1, (2, 3))\n",
    "\n",
    "c = tf.matmul(a,b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "TEP9UfjGCi6P",
    "outputId": "8be935b3-8b66-4393-d7d6-c34049b4ebd0"
   },
   "outputs": [],
   "source": [
    "print(c.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "AvKWDIwkEfW6",
    "outputId": "3340cfb0-8091-49c6-afe3-26f478bff333"
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(10, 3)\n",
    "w = np.random.randn(1, x.shape[1])\n",
    "b = np.random.randn(x.shape[0], 1)\n",
    "\n",
    "y_pred = tf.matmul(x, w, transpose_b=True) + b\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yBgiMgxMOb4g"
   },
   "source": [
    "### 0D Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "__NK54WsOflZ",
    "outputId": "6d64d373-5714-42df-efbf-8f87bd8d102b"
   },
   "outputs": [],
   "source": [
    "print(tf.add(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a0j3IcJBFlaF"
   },
   "source": [
    "### 1D Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "PMJKTLgSFrCc",
    "outputId": "07470ccd-65f5-4e18-c3d6-a9c6e10f872f"
   },
   "outputs": [],
   "source": [
    "_a = np.ones(5)\n",
    "_a = tf.multiply(_a, 1)\n",
    "print(_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "PMJKTLgSFrCc",
    "outputId": "07470ccd-65f5-4e18-c3d6-a9c6e10f872f"
   },
   "outputs": [],
   "source": [
    "print(_a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ENwXOmazFsaK"
   },
   "source": [
    "### 2D Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "8xf-1RiQFu_Y",
    "outputId": "4571cf23-51ee-4f55-a822-95efe208600e"
   },
   "outputs": [],
   "source": [
    "_b = np.ones([2, 5])\n",
    "_b = tf.multiply(_b, 1)\n",
    "print(_b)\n",
    "print(_b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xz9x4Ha-F5mi"
   },
   "source": [
    "### 3D Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "7f9AP06GF73L",
    "outputId": "8b8e4111-fd79-4c2c-d883-09d9d8d3b33b"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "file_path = keras.utils.get_file('cat.jpg', 'https://www.petmd.com/sites/default/files/what-does-it-mean-when-cat-wags-tail.jpg')\n",
    "img_raw = tf.io.read_file(file_path)\n",
    "print(repr(img_raw)[:100]+\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "SDYHlZ88GDHn",
    "outputId": "8219a750-11de-4c9e-d8fe-1694cdbd1ea9"
   },
   "outputs": [],
   "source": [
    "img_tensor = tf.image.decode_image(img_raw)\n",
    "\n",
    "print(img_tensor.shape)\n",
    "print(img_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "id": "h9QiaRztnSD3",
    "outputId": "5d6e63c4-0c4b-4d11-d9d4-cc434a54ab5c"
   },
   "outputs": [],
   "source": [
    "print(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "LNlZaf_XGXJd",
    "outputId": "cf514d4c-8b42-4f63-8d3b-a91cdbd8e86b"
   },
   "outputs": [],
   "source": [
    "img_final = tf.image.resize(img_tensor, [192, 192])\n",
    "img_final = img_final/255.0\n",
    "print(img_final.shape)\n",
    "print(img_final.numpy().min())\n",
    "print(img_final.numpy().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ES3Nw1szOv5h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OYIgSNrLOxBE"
   },
   "source": [
    "### Define a Linear Regression Model\n",
    "\n",
    "$\\hat{y} = w.x + b$\n",
    "\n",
    "$L(y, \\hat{y})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wLtJWvxtO2O9"
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "  def __init__(self):\n",
    "    self.W = None\n",
    "    self.b = None\n",
    "    \n",
    "  def __call__(self, x):\n",
    "    if self.W == None:\n",
    "      self.W = tf.Variable(tf.random.normal(shape=(1, x.shape[1])))\n",
    "    if self.b == None:\n",
    "      self.b = tf.Variable(tf.random.normal(shape=(x.shape[0], 1)))\n",
    "    return tf.matmul(x, self.W, transpose_b=True) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "ZvBxJwv8P27j",
    "outputId": "0e460fe2-8f45-40dd-fe65-ff1cec343b8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[6.9633856]\n",
      " [3.3688776]\n",
      " [6.135957 ]], shape=(3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "output = model(tf.constant([3.0, 3.1, 1.9, 2.0, 2.5, 2.9], shape=(3,2)))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GONYHg8VSAXw"
   },
   "source": [
    "### Define a Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "et0MBPYASCdH"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def loss(y_pred, y):\n",
    "  return tf.reduce_mean(tf.square(y-y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GWWLWRF0SYly"
   },
   "source": [
    "### Define a training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MGRir_F2SbIl"
   },
   "outputs": [],
   "source": [
    "def train(model, x, y, alpha):\n",
    "  x = tf.convert_to_tensor(x, np.float32) \n",
    "  y = tf.convert_to_tensor(y, np.float32)\n",
    "  with tf.GradientTape() as t:\n",
    "    t.watch(x)\n",
    "    current_loss = loss(model(x), y)\n",
    "  #print(current_loss)\n",
    "  dW, db = t.gradient(current_loss, [model.W, model.b])\n",
    "  #print(dW, db)\n",
    "  model.W.assign_sub(alpha * dW)\n",
    "  model.b.assign_sub(alpha * db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3CKRcBtdGZYd"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "NegvcOd4Vb_H",
    "outputId": "5aa936d6-2467-4dd0-904a-c550efa95e20"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "\n",
    "df = pd.read_csv('./boston/train.csv', index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wdWOnERKWY0T"
   },
   "outputs": [],
   "source": [
    "train_df = df.sample(frac=0.8,random_state=0)\n",
    "test_df = df.drop(train_df.index)\n",
    "\n",
    "columns = ['nox', 'rm', 'chas', 'dis', 'ptratio', 'lstat', 'rad']\n",
    "\n",
    "X_train = train_df[columns].values\n",
    "X_test = test_df[columns].values\n",
    "y_train = train_df[['medv']].values\n",
    "y_test = test_df[['medv']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>chas</th>\n",
       "      <th>dis</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>lstat</th>\n",
       "      <th>rad</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>15.2</td>\n",
       "      <td>12.43</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nox     rm  chas     dis  ptratio  lstat  rad\n",
       "ID                                                 \n",
       "1   0.538  6.575     0  4.0900     15.3   4.98    1\n",
       "2   0.469  6.421     0  4.9671     17.8   9.14    2\n",
       "4   0.458  6.998     0  6.0622     18.7   2.94    3\n",
       "5   0.458  7.147     0  6.0622     18.7   5.33    3\n",
       "7   0.524  6.012     0  5.5605     15.2  12.43    5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    medv\n",
       "ID      \n",
       "1   24.0\n",
       "2   21.6\n",
       "4   33.4\n",
       "5   36.2\n",
       "7   22.9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['medv']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TKFSncsZTSrm"
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "train(model, X_train, y_train, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uWZua09J32cw"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s_D1kaxH31zK"
   },
   "outputs": [],
   "source": [
    "class LogisticModel(object):\n",
    "  def __init__(self):\n",
    "    self.W = None\n",
    "    self.b = None\n",
    "    \n",
    "  def __call__(self, x):\n",
    "    if self.W == None:\n",
    "      self.W = tf.Variable(tf.random.normal(shape=(1, x.shape[1])))\n",
    "    if self.b == None:\n",
    "      self.b = tf.Variable(tf.random.normal(shape=(x.shape[0], 1)))\n",
    "    y = tf.matmul(x, self.W, transpose_b=True) + self.b\n",
    "    return tf.math.sigmoid(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VL4XiQrjTMUf"
   },
   "source": [
    "### Train for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(1, 7) dtype=float32, numpy=\n",
      "array([[ 1.0251641 , 23.1939    , -0.73740137, 14.599553  , 66.53072   ,\n",
      "        39.247177  , 26.141218  ]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "print(model.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GqTaPEZvOrQ2"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mequal\u001b[0;34m(x, y, incompatible_shape_error, name)\u001b[0m\n\u001b[1;32m   3605\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3606\u001b[0;31m         \"incompatible_shape_error\", incompatible_shape_error)\n\u001b[0m\u001b[1;32m   3607\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_FallbackException\u001b[0m: This function does not handle the case of the path where all inputs are not already EagerTensors.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5fc626c15168>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-cc7981b91728>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, x, y, alpha)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;31m#print(current_loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mdW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-78115e321d1d>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincompatible_shape_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m       \u001b[0;31m# In legacy graph mode, tensor equality is object equality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mequal\u001b[0;34m(x, y, incompatible_shape_error, name)\u001b[0m\n\u001b[1;32m   3610\u001b[0m         return equal_eager_fallback(\n\u001b[1;32m   3611\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincompatible_shape_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mincompatible_shape_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3612\u001b[0;31m             name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m   3613\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3614\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mequal_eager_fallback\u001b[0;34m(x, y, incompatible_shape_error, name, ctx)\u001b[0m\n\u001b[1;32m   3650\u001b[0m     \u001b[0mincompatible_shape_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3651\u001b[0m   \u001b[0mincompatible_shape_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincompatible_shape_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"incompatible_shape_error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3652\u001b[0;31m   \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_inputs_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3653\u001b[0m   \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_inputs_T\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, default_dtype)\u001b[0m\n\u001b[1;32m    255\u001b[0m       ret.append(\n\u001b[1;32m    256\u001b[0m           internal_convert_to_tensor(\n\u001b[0;32m--> 257\u001b[0;31m               t, dtype, preferred_dtype=default_dtype, ctx=ctx))\n\u001b[0m\u001b[1;32m    258\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_composite_tensors)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    284\u001b[0m                                          as_ref=False):\n\u001b[1;32m    285\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    225\u001b[0m   \"\"\"\n\u001b[1;32m    226\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 227\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    233\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "model = Model()\n",
    "for i in range(epochs):\n",
    "  train(model, X_train, y_train, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "1HFwVRUr1i9c",
    "outputId": "fc781f81-ebf4-4c4a-f3da-0b396d9a5cbd"
   },
   "outputs": [],
   "source": [
    "print(model.W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2VOpy2p8ZEEN"
   },
   "source": [
    "## Tensorflow with Keras API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GJ6Ji03UVXHz"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "6CmoYYAyWtsu",
    "outputId": "e3707824-5cff-440a-a09b-9b5e38e41b28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                80        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define a neural network\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 8         \n",
      "=================================================================\n",
      "Total params: 8\n",
      "Trainable params: 8\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define a linear model with a regression output\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1, input_shape=(X_train.shape[1],))\n",
    "])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A3p1zPIjYz0r"
   },
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(0.001)\n",
    "model.compile(optimizer=adam, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tzu3kOpkZBcB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 239 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "239/239 [==============================] - 1s 2ms/sample - loss: 908.0616 - val_loss: 780.0603\n",
      "Epoch 2/100\n",
      "239/239 [==============================] - 0s 77us/sample - loss: 859.3132 - val_loss: 734.5468\n",
      "Epoch 3/100\n",
      "239/239 [==============================] - 0s 71us/sample - loss: 813.4574 - val_loss: 692.3656\n",
      "Epoch 4/100\n",
      "239/239 [==============================] - 0s 114us/sample - loss: 770.5230 - val_loss: 653.8230\n",
      "Epoch 5/100\n",
      "239/239 [==============================] - 0s 103us/sample - loss: 730.0578 - val_loss: 617.9487\n",
      "Epoch 6/100\n",
      "239/239 [==============================] - 0s 99us/sample - loss: 692.1219 - val_loss: 584.1835\n",
      "Epoch 7/100\n",
      "239/239 [==============================] - 0s 107us/sample - loss: 656.8638 - val_loss: 551.5739\n",
      "Epoch 8/100\n",
      "239/239 [==============================] - 0s 87us/sample - loss: 622.8188 - val_loss: 520.6196\n",
      "Epoch 9/100\n",
      "239/239 [==============================] - 0s 116us/sample - loss: 590.3013 - val_loss: 491.1806\n",
      "Epoch 10/100\n",
      "239/239 [==============================] - 0s 92us/sample - loss: 559.1319 - val_loss: 463.0692\n",
      "Epoch 11/100\n",
      "239/239 [==============================] - 0s 103us/sample - loss: 528.9852 - val_loss: 436.2063\n",
      "Epoch 12/100\n",
      "239/239 [==============================] - 0s 114us/sample - loss: 500.0293 - val_loss: 410.3089\n",
      "Epoch 13/100\n",
      "239/239 [==============================] - 0s 102us/sample - loss: 472.2245 - val_loss: 385.3322\n",
      "Epoch 14/100\n",
      "239/239 [==============================] - 0s 96us/sample - loss: 445.4246 - val_loss: 361.4936\n",
      "Epoch 15/100\n",
      "239/239 [==============================] - 0s 92us/sample - loss: 419.4644 - val_loss: 338.7422\n",
      "Epoch 16/100\n",
      "239/239 [==============================] - 0s 116us/sample - loss: 394.7897 - val_loss: 316.9689\n",
      "Epoch 17/100\n",
      "239/239 [==============================] - 0s 92us/sample - loss: 370.8055 - val_loss: 296.0458\n",
      "Epoch 18/100\n",
      "239/239 [==============================] - 0s 87us/sample - loss: 347.8583 - val_loss: 275.9787\n",
      "Epoch 19/100\n",
      "239/239 [==============================] - 0s 127us/sample - loss: 326.0112 - val_loss: 257.6331\n",
      "Epoch 20/100\n",
      "239/239 [==============================] - 0s 122us/sample - loss: 306.1569 - val_loss: 240.5490\n",
      "Epoch 21/100\n",
      "239/239 [==============================] - 0s 120us/sample - loss: 287.5319 - val_loss: 225.1694\n",
      "Epoch 22/100\n",
      "239/239 [==============================] - 0s 97us/sample - loss: 271.0136 - val_loss: 211.1316\n",
      "Epoch 23/100\n",
      "239/239 [==============================] - 0s 79us/sample - loss: 256.0011 - val_loss: 198.5868\n",
      "Epoch 24/100\n",
      "239/239 [==============================] - 0s 85us/sample - loss: 242.4616 - val_loss: 187.7312\n",
      "Epoch 25/100\n",
      "239/239 [==============================] - 0s 98us/sample - loss: 230.5294 - val_loss: 178.4624\n",
      "Epoch 26/100\n",
      "239/239 [==============================] - 0s 97us/sample - loss: 220.2380 - val_loss: 170.5100\n",
      "Epoch 27/100\n",
      "239/239 [==============================] - 0s 92us/sample - loss: 211.4803 - val_loss: 163.8154\n",
      "Epoch 28/100\n",
      "239/239 [==============================] - 0s 98us/sample - loss: 203.5684 - val_loss: 158.2143\n",
      "Epoch 29/100\n",
      "239/239 [==============================] - 0s 95us/sample - loss: 197.0780 - val_loss: 153.2559\n",
      "Epoch 30/100\n",
      "239/239 [==============================] - 0s 96us/sample - loss: 191.2479 - val_loss: 149.2675\n",
      "Epoch 31/100\n",
      "239/239 [==============================] - 0s 114us/sample - loss: 186.5941 - val_loss: 145.9416\n",
      "Epoch 32/100\n",
      "239/239 [==============================] - 0s 110us/sample - loss: 182.8596 - val_loss: 143.0191\n",
      "Epoch 33/100\n",
      "239/239 [==============================] - 0s 107us/sample - loss: 178.7170 - val_loss: 140.6985\n",
      "Epoch 34/100\n",
      "239/239 [==============================] - 0s 95us/sample - loss: 175.6605 - val_loss: 138.4779\n",
      "Epoch 35/100\n",
      "239/239 [==============================] - 0s 96us/sample - loss: 172.4952 - val_loss: 136.5885\n",
      "Epoch 36/100\n",
      "239/239 [==============================] - 0s 97us/sample - loss: 170.0924 - val_loss: 134.7648\n",
      "Epoch 37/100\n",
      "239/239 [==============================] - 0s 91us/sample - loss: 167.2617 - val_loss: 133.1342\n",
      "Epoch 38/100\n",
      "239/239 [==============================] - 0s 68us/sample - loss: 164.9465 - val_loss: 131.5342\n",
      "Epoch 39/100\n",
      "239/239 [==============================] - 0s 95us/sample - loss: 162.7668 - val_loss: 130.0178\n",
      "Epoch 40/100\n",
      "239/239 [==============================] - 0s 79us/sample - loss: 160.6091 - val_loss: 128.5208\n",
      "Epoch 41/100\n",
      "239/239 [==============================] - 0s 85us/sample - loss: 158.5258 - val_loss: 127.0296\n",
      "Epoch 42/100\n",
      "239/239 [==============================] - 0s 76us/sample - loss: 156.4217 - val_loss: 125.6852\n",
      "Epoch 43/100\n",
      "239/239 [==============================] - 0s 77us/sample - loss: 154.4522 - val_loss: 124.2995\n",
      "Epoch 44/100\n",
      "239/239 [==============================] - 0s 85us/sample - loss: 152.4406 - val_loss: 122.9907\n",
      "Epoch 45/100\n",
      "239/239 [==============================] - 0s 68us/sample - loss: 150.6723 - val_loss: 121.7265\n",
      "Epoch 46/100\n",
      "239/239 [==============================] - 0s 91us/sample - loss: 148.7107 - val_loss: 120.4695\n",
      "Epoch 47/100\n",
      "239/239 [==============================] - 0s 75us/sample - loss: 146.9570 - val_loss: 119.1216\n",
      "Epoch 48/100\n",
      "239/239 [==============================] - 0s 68us/sample - loss: 145.1460 - val_loss: 117.8678\n",
      "Epoch 49/100\n",
      "239/239 [==============================] - 0s 83us/sample - loss: 143.3671 - val_loss: 116.6938\n",
      "Epoch 50/100\n",
      "239/239 [==============================] - 0s 85us/sample - loss: 141.6783 - val_loss: 115.5102\n",
      "Epoch 51/100\n",
      "239/239 [==============================] - 0s 90us/sample - loss: 140.0458 - val_loss: 114.3681\n",
      "Epoch 52/100\n",
      "239/239 [==============================] - 0s 96us/sample - loss: 138.4332 - val_loss: 113.3098\n",
      "Epoch 53/100\n",
      "239/239 [==============================] - 0s 102us/sample - loss: 136.7216 - val_loss: 112.1723\n",
      "Epoch 54/100\n",
      "239/239 [==============================] - 0s 84us/sample - loss: 135.1106 - val_loss: 110.9920\n",
      "Epoch 55/100\n",
      "239/239 [==============================] - 0s 76us/sample - loss: 133.5851 - val_loss: 109.8787\n",
      "Epoch 56/100\n",
      "239/239 [==============================] - 0s 81us/sample - loss: 131.9542 - val_loss: 108.8639\n",
      "Epoch 57/100\n",
      "239/239 [==============================] - 0s 83us/sample - loss: 130.4928 - val_loss: 107.7862\n",
      "Epoch 58/100\n",
      "239/239 [==============================] - 0s 78us/sample - loss: 128.9842 - val_loss: 106.6535\n",
      "Epoch 59/100\n",
      "239/239 [==============================] - 0s 83us/sample - loss: 127.4696 - val_loss: 105.6527\n",
      "Epoch 60/100\n",
      "239/239 [==============================] - 0s 83us/sample - loss: 125.9959 - val_loss: 104.6321\n",
      "Epoch 61/100\n",
      "239/239 [==============================] - 0s 97us/sample - loss: 124.6144 - val_loss: 103.6610\n",
      "Epoch 62/100\n",
      "239/239 [==============================] - 0s 114us/sample - loss: 123.1527 - val_loss: 102.5627\n",
      "Epoch 63/100\n",
      "239/239 [==============================] - ETA: 0s - loss: 95.81 - 0s 107us/sample - loss: 121.6935 - val_loss: 101.5499\n",
      "Epoch 64/100\n",
      "239/239 [==============================] - 0s 94us/sample - loss: 120.2659 - val_loss: 100.6339\n",
      "Epoch 65/100\n",
      "239/239 [==============================] - 0s 101us/sample - loss: 118.9006 - val_loss: 99.7567\n",
      "Epoch 66/100\n",
      "239/239 [==============================] - 0s 106us/sample - loss: 117.5763 - val_loss: 98.9015\n",
      "Epoch 67/100\n",
      "239/239 [==============================] - 0s 98us/sample - loss: 116.1399 - val_loss: 98.0179\n",
      "Epoch 68/100\n",
      "239/239 [==============================] - 0s 128us/sample - loss: 114.8477 - val_loss: 97.1710\n",
      "Epoch 69/100\n",
      "239/239 [==============================] - 0s 99us/sample - loss: 113.5791 - val_loss: 96.2737\n",
      "Epoch 70/100\n",
      "239/239 [==============================] - 0s 81us/sample - loss: 112.2929 - val_loss: 95.3847\n",
      "Epoch 71/100\n",
      "239/239 [==============================] - 0s 80us/sample - loss: 111.0170 - val_loss: 94.4492\n",
      "Epoch 72/100\n",
      "239/239 [==============================] - 0s 98us/sample - loss: 109.7016 - val_loss: 93.6281\n",
      "Epoch 73/100\n",
      "239/239 [==============================] - 0s 103us/sample - loss: 108.4569 - val_loss: 92.8229\n",
      "Epoch 74/100\n",
      "239/239 [==============================] - 0s 96us/sample - loss: 107.2404 - val_loss: 92.1213\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 0s 94us/sample - loss: 106.0081 - val_loss: 91.4315\n",
      "Epoch 76/100\n",
      "239/239 [==============================] - 0s 102us/sample - loss: 104.8760 - val_loss: 90.5792\n",
      "Epoch 77/100\n",
      "239/239 [==============================] - 0s 88us/sample - loss: 103.6941 - val_loss: 89.7965\n",
      "Epoch 78/100\n",
      "239/239 [==============================] - 0s 77us/sample - loss: 102.6047 - val_loss: 89.1394\n",
      "Epoch 79/100\n",
      "239/239 [==============================] - 0s 86us/sample - loss: 101.5401 - val_loss: 88.4529\n",
      "Epoch 80/100\n",
      "239/239 [==============================] - 0s 91us/sample - loss: 100.3564 - val_loss: 87.6289\n",
      "Epoch 81/100\n",
      "239/239 [==============================] - 0s 74us/sample - loss: 99.3137 - val_loss: 86.8917\n",
      "Epoch 82/100\n",
      "239/239 [==============================] - 0s 83us/sample - loss: 98.2568 - val_loss: 86.1830\n",
      "Epoch 83/100\n",
      "239/239 [==============================] - 0s 76us/sample - loss: 97.2479 - val_loss: 85.4433\n",
      "Epoch 84/100\n",
      "239/239 [==============================] - 0s 88us/sample - loss: 96.2457 - val_loss: 84.7882\n",
      "Epoch 85/100\n",
      "239/239 [==============================] - 0s 82us/sample - loss: 95.2133 - val_loss: 84.1759\n",
      "Epoch 86/100\n",
      "239/239 [==============================] - 0s 71us/sample - loss: 94.1819 - val_loss: 83.6601\n",
      "Epoch 87/100\n",
      "239/239 [==============================] - 0s 74us/sample - loss: 93.2188 - val_loss: 83.1441\n",
      "Epoch 88/100\n",
      "239/239 [==============================] - 0s 89us/sample - loss: 92.2769 - val_loss: 82.4968\n",
      "Epoch 89/100\n",
      "239/239 [==============================] - 0s 82us/sample - loss: 91.3452 - val_loss: 81.8947\n",
      "Epoch 90/100\n",
      "239/239 [==============================] - 0s 79us/sample - loss: 90.4278 - val_loss: 81.3096\n",
      "Epoch 91/100\n",
      "239/239 [==============================] - 0s 81us/sample - loss: 89.5454 - val_loss: 80.7323\n",
      "Epoch 92/100\n",
      "239/239 [==============================] - 0s 81us/sample - loss: 88.5883 - val_loss: 80.2698\n",
      "Epoch 93/100\n",
      "239/239 [==============================] - 0s 76us/sample - loss: 87.7684 - val_loss: 79.7143\n",
      "Epoch 94/100\n",
      "239/239 [==============================] - 0s 78us/sample - loss: 86.8216 - val_loss: 79.1091\n",
      "Epoch 95/100\n",
      "239/239 [==============================] - 0s 80us/sample - loss: 85.9877 - val_loss: 78.5181\n",
      "Epoch 96/100\n",
      "239/239 [==============================] - 0s 85us/sample - loss: 85.1860 - val_loss: 77.9817\n",
      "Epoch 97/100\n",
      "239/239 [==============================] - 0s 78us/sample - loss: 84.3800 - val_loss: 77.4465\n",
      "Epoch 98/100\n",
      "239/239 [==============================] - 0s 77us/sample - loss: 83.5516 - val_loss: 77.0105\n",
      "Epoch 99/100\n",
      "239/239 [==============================] - 0s 78us/sample - loss: 82.7664 - val_loss: 76.5533\n",
      "Epoch 100/100\n",
      "239/239 [==============================] - 0s 86us/sample - loss: 81.9980 - val_loss: 76.1517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x62eb47710>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = pd.DataFrame({'actuals': y_test.reshape(-1), 'predicted': y_pred.reshape(-1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actuals</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>24.604994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>24.7</td>\n",
       "      <td>23.737633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.628204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>19.7</td>\n",
       "      <td>23.315868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20.5</td>\n",
       "      <td>23.581490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>26.026188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>18.7</td>\n",
       "      <td>24.974365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>33.0</td>\n",
       "      <td>27.869051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>24.2</td>\n",
       "      <td>24.386507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>20.8</td>\n",
       "      <td>22.616060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actuals  predicted\n",
       "0     18.2  24.604994\n",
       "1     24.7  23.737633\n",
       "2     20.0  22.628204\n",
       "3     19.7  23.315868\n",
       "4     20.5  23.581490\n",
       "5     23.3  26.026188\n",
       "6     18.7  24.974365\n",
       "7     33.0  27.869051\n",
       "8     24.2  24.386507\n",
       "9     20.8  22.616060"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SAS92NoE7tQ-"
   },
   "source": [
    "### Can we engineer new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tfRd65D31SLW"
   },
   "outputs": [],
   "source": [
    "# we need a new way of getting data into the model\n",
    "def df_to_dataset(df, columns, shuffle=True, batch_size=64):\n",
    "  df = df.copy()\n",
    "  labels = df.pop('medv')\n",
    "  features_df = df[columns]\n",
    "  ds = tf.data.Dataset.from_tensor_slices( (dict(features_df), labels) )\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(df))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "36THDaD75Mvz"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, val = train_test_split(df, test_size=0.1)\n",
    "train_ds = df_to_dataset(train, columns)\n",
    "val_ds = df_to_dataset(val, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "eZgboWHG6onz",
    "outputId": "7b0add91-b31a-49ee-ed34-8bbefca03710"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>chas</th>\n",
       "      <th>dis</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>lstat</th>\n",
       "      <th>rad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.557144</td>\n",
       "      <td>6.265619</td>\n",
       "      <td>0.060060</td>\n",
       "      <td>3.709934</td>\n",
       "      <td>18.448048</td>\n",
       "      <td>12.515435</td>\n",
       "      <td>9.633634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.114955</td>\n",
       "      <td>0.703952</td>\n",
       "      <td>0.237956</td>\n",
       "      <td>1.981123</td>\n",
       "      <td>2.151821</td>\n",
       "      <td>7.067781</td>\n",
       "      <td>8.742174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.453000</td>\n",
       "      <td>5.884000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.122400</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>7.180000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.202000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.092300</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.970000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>6.595000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.116700</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>16.420000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.725000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.710300</td>\n",
       "      <td>21.200000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              nox          rm        chas         dis     ptratio       lstat  \\\n",
       "count  333.000000  333.000000  333.000000  333.000000  333.000000  333.000000   \n",
       "mean     0.557144    6.265619    0.060060    3.709934   18.448048   12.515435   \n",
       "std      0.114955    0.703952    0.237956    1.981123    2.151821    7.067781   \n",
       "min      0.385000    3.561000    0.000000    1.129600   12.600000    1.730000   \n",
       "25%      0.453000    5.884000    0.000000    2.122400   17.400000    7.180000   \n",
       "50%      0.538000    6.202000    0.000000    3.092300   19.000000   10.970000   \n",
       "75%      0.631000    6.595000    0.000000    5.116700   20.200000   16.420000   \n",
       "max      0.871000    8.725000    1.000000   10.710300   21.200000   37.970000   \n",
       "\n",
       "              rad  \n",
       "count  333.000000  \n",
       "mean     9.633634  \n",
       "std      8.742174  \n",
       "min      1.000000  \n",
       "25%      4.000000  \n",
       "50%      5.000000  \n",
       "75%     24.000000  \n",
       "max     24.000000  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5x6xfP20yLc-"
   },
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "\n",
    "# numeric columns\n",
    "for _col in columns:\n",
    "  feature_columns.append(tf.feature_column.numeric_column(_col))\n",
    "  \n",
    "# bucketize number of rooms\n",
    "rm_buckets = tf.feature_column.bucketized_column(tf.feature_column.numeric_column('rm'), boundaries=[1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "rad_buckets = tf.feature_column.bucketized_column(tf.feature_column.numeric_column('rad'), boundaries=[1, 5, 10])\n",
    "nox_buckets = tf.feature_column.bucketized_column(tf.feature_column.numeric_column('nox'), boundaries=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "\n",
    "feature_columns.append(rm_buckets)\n",
    "feature_columns.append(rad_buckets)\n",
    "feature_columns.append(nox_buckets)\n",
    "\n",
    "# cross rooms and nox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vE8DshK1zaLD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 506.5299 - val_loss: 0.0000e+00\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 484.0879 - val_loss: 522.7888\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 475.9933 - val_loss: 505.7102\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 462.6585 - val_loss: 489.0371\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 448.7806 - val_loss: 472.8332\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 428.3048 - val_loss: 457.0757\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 408.9639 - val_loss: 441.6085\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 380.8148 - val_loss: 426.7402\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 386.7602 - val_loss: 412.2796\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 369.3383 - val_loss: 398.1866\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 348.6545 - val_loss: 384.3853\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 337.8306 - val_loss: 370.7595\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 322.4290 - val_loss: 357.2595\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 303.3241 - val_loss: 344.1624\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 280.1467 - val_loss: 331.5144\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 283.8877 - val_loss: 319.2667\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 272.8602 - val_loss: 307.7922\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 255.2106 - val_loss: 296.9018\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 250.7702 - val_loss: 286.6452\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 241.6494 - val_loss: 277.0503\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 233.0439 - val_loss: 268.0497\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 210.9387 - val_loss: 259.7607\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 216.3620 - val_loss: 252.0061\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 206.9212 - val_loss: 244.9305\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 197.1878 - val_loss: 238.5757\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 191.1772 - val_loss: 232.7009\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 167.5925 - val_loss: 227.5235\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 176.1239 - val_loss: 222.7809\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 170.8420 - val_loss: 218.4695\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 170.7922 - val_loss: 214.6461\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 150.4441 - val_loss: 211.1601\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 155.3436 - val_loss: 207.9188\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 159.2549 - val_loss: 204.8712\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 153.5356 - val_loss: 202.0146\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 156.8896 - val_loss: 199.2628\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 151.1842 - val_loss: 196.5712\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 136.1601 - val_loss: 193.9059\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 147.7306 - val_loss: 191.1795\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 145.8090 - val_loss: 188.5299\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 137.6909 - val_loss: 185.7377\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 138.0160 - val_loss: 182.9133\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 136.0006 - val_loss: 180.1320\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 134.4103 - val_loss: 177.4099\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 137.1514 - val_loss: 174.5838\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 136.1664 - val_loss: 171.7218\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 133.4810 - val_loss: 168.8402\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 122.6651 - val_loss: 165.9461\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 118.6939 - val_loss: 163.0312\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 121.1342 - val_loss: 160.1335\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 122.9823 - val_loss: 157.2591\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 118.3346 - val_loss: 154.3796\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 118.6139 - val_loss: 151.5409\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 120.4290 - val_loss: 148.7517\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 112.6364 - val_loss: 146.1062\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.0411 - val_loss: 143.4432\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 117.2873 - val_loss: 140.8194\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 113.0259 - val_loss: 138.3215\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 115.1158 - val_loss: 135.8494\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.5758 - val_loss: 133.4190\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.1878 - val_loss: 130.8828\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.0962 - val_loss: 128.4471\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.0016 - val_loss: 126.0665\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.7044 - val_loss: 123.7245\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.9223 - val_loss: 121.3893\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.1611 - val_loss: 119.1413\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.7102 - val_loss: 116.8947\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.4639 - val_loss: 114.7316\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.3587 - val_loss: 112.6067\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 94.8042 - val_loss: 110.5314\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.7891 - val_loss: 108.4369\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.8214 - val_loss: 106.4379\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.4184 - val_loss: 104.4570\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.7119 - val_loss: 102.6247\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.8508 - val_loss: 100.8655\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 92.1763 - val_loss: 99.1777\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.5794 - val_loss: 97.5062\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.7861 - val_loss: 95.8457\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.4584 - val_loss: 94.2455\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.7847 - val_loss: 92.6938\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 91.5341 - val_loss: 91.2318\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.8404 - val_loss: 89.7976\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 88.5926 - val_loss: 88.4234\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 84.2603 - val_loss: 87.0627\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 83.8846 - val_loss: 85.7603\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 86.4399 - val_loss: 84.3915\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 84.6458 - val_loss: 83.0794\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 79.5490 - val_loss: 81.7476\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 80.3732 - val_loss: 80.4949\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 78.2896 - val_loss: 79.3270\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 76.3779 - val_loss: 78.1452\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 70.7851 - val_loss: 76.9902\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 70.5913 - val_loss: 75.8364\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 81.0660 - val_loss: 74.6721\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 65.8377 - val_loss: 73.6333\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 72.2146 - val_loss: 72.5778\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 72.2557 - val_loss: 71.5292\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 71.2600 - val_loss: 70.5088\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 67.8520 - val_loss: 69.5325\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 73.1551 - val_loss: 68.6057\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 69.3811 - val_loss: 67.6947\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 75.9918 - val_loss: 66.7816\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 70.3159 - val_loss: 65.9864\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 70.5254 - val_loss: 65.2022\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 69.6891 - val_loss: 64.4332\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 66.0123 - val_loss: 63.6367\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 66.3036 - val_loss: 62.8919\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 63.0146 - val_loss: 62.0546\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 67.6647 - val_loss: 61.3064\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 71.0818 - val_loss: 60.5302\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 69.4720 - val_loss: 59.8411\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 66.7754 - val_loss: 59.2058\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 64.8839 - val_loss: 58.5628\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 59.3364 - val_loss: 57.9740\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 68.5541 - val_loss: 57.3419\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 57.6349 - val_loss: 56.7396\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 64.3137 - val_loss: 56.1208\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 61.0871 - val_loss: 55.5285\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.1277 - val_loss: 54.9201\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 61.1320 - val_loss: 54.3359\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 60.9824 - val_loss: 53.7745\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 56.4199 - val_loss: 53.2511\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 60.9826 - val_loss: 52.7071\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 62.4023 - val_loss: 52.2082\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 59.5862 - val_loss: 51.7005\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 58.0877 - val_loss: 51.2395\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 57.3709 - val_loss: 50.7676\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54.6825 - val_loss: 50.3054\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 59.0328 - val_loss: 49.8110\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 51.3193 - val_loss: 49.3642\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 57.5517 - val_loss: 48.8976\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 52.4155 - val_loss: 48.4966\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 53.6104 - val_loss: 48.0528\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 54.7869 - val_loss: 47.6336\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 54.3945 - val_loss: 47.2193\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 56.1064 - val_loss: 46.8265\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 57.2007 - val_loss: 46.4454\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 54.0540 - val_loss: 46.1210\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 49.6471 - val_loss: 45.8081\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 47.0926 - val_loss: 45.4746\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 53.1051 - val_loss: 45.1295\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.3898 - val_loss: 44.8007\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 49.7434 - val_loss: 44.4723\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.6307 - val_loss: 44.1513\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 50.7919 - val_loss: 43.8284\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.0677 - val_loss: 43.5274\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.5979 - val_loss: 43.1989\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.4310 - val_loss: 42.9068\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.4429 - val_loss: 42.6327\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.3004 - val_loss: 42.3369\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 49.3181 - val_loss: 42.0760\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.3523 - val_loss: 41.8269\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.3660 - val_loss: 41.5590\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 46.8209 - val_loss: 41.3107\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 48.5405 - val_loss: 41.0626\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 50.5611 - val_loss: 40.8063\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.0269 - val_loss: 40.5631\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 45.6681 - val_loss: 40.3610\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.6548 - val_loss: 40.1394\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.4118 - val_loss: 39.9355\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.3886 - val_loss: 39.7043\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 46.0181 - val_loss: 39.4817\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 45.9756 - val_loss: 39.2800\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.9458 - val_loss: 39.0716\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 47.2251 - val_loss: 38.8607\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 43.4416 - val_loss: 38.7034\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 40.6936 - val_loss: 38.4792\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44.4744 - val_loss: 38.2744\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 42.4463 - val_loss: 38.0735\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 46.5611 - val_loss: 37.8779\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 41.7956 - val_loss: 37.6942\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 46.0652 - val_loss: 37.5148\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 41.7777 - val_loss: 37.3491\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 40.8184 - val_loss: 37.1799\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 39.7211 - val_loss: 37.0271\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 41.8454 - val_loss: 36.8725\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 41.0076 - val_loss: 36.7189\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 43.4880 - val_loss: 36.5395\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 39.0046 - val_loss: 36.3670\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 39.1886 - val_loss: 36.2158\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 41.1304 - val_loss: 36.0695\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 40.8278 - val_loss: 35.9331\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.8281 - val_loss: 35.7658\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 42.5938 - val_loss: 35.6096\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 37.5138 - val_loss: 35.4620\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 40.4797 - val_loss: 35.3272\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 40.7669 - val_loss: 35.1829\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 40.7411 - val_loss: 35.0571\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 40.8689 - val_loss: 34.9195\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 42.0751 - val_loss: 34.7819\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 40.0762 - val_loss: 34.6535\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 37.1219 - val_loss: 34.5159\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 36.1518 - val_loss: 34.3942\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 37.2123 - val_loss: 34.2689\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 37.1673 - val_loss: 34.1511\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 40.3517 - val_loss: 34.0087\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 36.7158 - val_loss: 33.8953\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 39.0419 - val_loss: 33.7569\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 38.3142 - val_loss: 33.6203\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 38.6983 - val_loss: 33.4931\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 37.8169 - val_loss: 33.3793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3ad07ed0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresLayer = keras.layers.DenseFeatures(feature_columns)\n",
    "model = keras.Sequential([\n",
    "    featuresLayer,\n",
    "    keras.layers.Dense(50, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(train_ds, epochs=200, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "_c = pd.DataFrame({'actuals': val['medv'], 'predicted':y_preds.reshape(-1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actuals</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>345</td>\n",
       "      <td>31.2</td>\n",
       "      <td>29.459932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>50.0</td>\n",
       "      <td>12.835381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>353</td>\n",
       "      <td>18.6</td>\n",
       "      <td>17.685524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>18.2</td>\n",
       "      <td>14.355935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>482</td>\n",
       "      <td>23.7</td>\n",
       "      <td>30.157345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>478</td>\n",
       "      <td>12.0</td>\n",
       "      <td>36.572540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>42.8</td>\n",
       "      <td>20.001629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>19.4</td>\n",
       "      <td>12.120832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>21.2</td>\n",
       "      <td>23.368683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>17.4</td>\n",
       "      <td>32.473309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actuals  predicted\n",
       "ID                     \n",
       "345     31.2  29.459932\n",
       "226     50.0  12.835381\n",
       "353     18.6  17.685524\n",
       "15      18.2  14.355935\n",
       "482     23.7  30.157345\n",
       "478     12.0  36.572540\n",
       "254     42.8  20.001629\n",
       "154     19.4  12.120832\n",
       "117     21.2  23.368683\n",
       "171     17.4  32.473309"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_c.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nRZr21L_mkBW"
   },
   "source": [
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P-R8o11vz-GO"
   },
   "source": [
    "### TensorFlow Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pR1xaQOHMk9r"
   },
   "outputs": [],
   "source": [
    "def train_fn():\n",
    "  df = train_df.copy()\n",
    "  labels = df.pop('medv')\n",
    "  features_df = df[columns]\n",
    "  ds = tf.data.Dataset.from_tensor_slices( (dict(features_df), labels) )\n",
    "  ds = ds.shuffle(1000).batch(64).repeat(5)\n",
    "  \n",
    "  return ds\n",
    "\n",
    "def val_fn():\n",
    "  df = test_df.copy()\n",
    "  labels = df.pop('medv')\n",
    "  features_df = df[columns]\n",
    "  ds = tf.data.Dataset.from_tensor_slices( (dict(features_df), labels) )\n",
    "  ds = ds.batch(64).repeat(1)\n",
    "  \n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "TbqiDK2g0BV-",
    "outputId": "3c1a3d7f-5fe4-4f03-c5f7-8d9082ee8d4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/xm/rvswt1sx4rdf56_wpqz5rt4c0000gn/T/tmp71smebtj\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/xm/rvswt1sx4rdf56_wpqz5rt4c0000gn/T/tmp71smebtj', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a3c504b10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "id": "_UcNfxrCMVfu",
    "outputId": "52b3ed9f-7e69-4304-a09d-e9ff6a6c8c45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/robert/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/robert/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From /Users/robert/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:518: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /Users/robert/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /Users/robert/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/ftrl.py:143: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/xm/rvswt1sx4rdf56_wpqz5rt4c0000gn/T/tmp71smebtj/model.ckpt.\n",
      "INFO:tensorflow:loss = 662.3889, step = 0\n",
      "INFO:tensorflow:Saving checkpoints for 25 into /var/folders/xm/rvswt1sx4rdf56_wpqz5rt4c0000gn/T/tmp71smebtj/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 244.9428.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearRegressorV2 at 0x1a3c4b56d0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn=train_fn, steps=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4gn2TQ8w9M0O"
   },
   "source": [
    "## Afternoon\n",
    "### Pytorch 1.0\n",
    "* You should probably restart the runtime at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QVz0B-Gh8lUr"
   },
   "outputs": [],
   "source": [
    "! pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QV7w1PV6eRLz"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "hLrVRWmidytM",
    "outputId": "cc4750fd-0af5-4ebf-f95d-494fd5b35afb"
   },
   "outputs": [],
   "source": [
    "a = torch.rand(2,2)\n",
    "b = torch.rand(2,2)\n",
    "c = a + b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "QZxN9EZGePJT",
    "outputId": "28eb4b05-234b-4d43-ca73-57c487d3bf11"
   },
   "outputs": [],
   "source": [
    "d = torch.add(a, b)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "QhfcL3nWedPP",
    "outputId": "fda1a117-5805-434c-8e2f-20c1abf8d6c7"
   },
   "outputs": [],
   "source": [
    "# a += 5\n",
    "print(a)\n",
    "a.add_(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "XEvEHLwhiaeN",
    "outputId": "366ac16a-91c2-4366-eeea-e25c17980f7b"
   },
   "outputs": [],
   "source": [
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "ynXT1y4DernW",
    "outputId": "41041433-6616-4b2c-ac83-4475befc54e0"
   },
   "outputs": [],
   "source": [
    "print(a * b)\n",
    "print(a)\n",
    "a.mul(b)\n",
    "print(a)\n",
    "a.mul_(b)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "eGnyY6oxe-nN",
    "outputId": "9afe7239-5e6f-4433-9509-51f17c7cab10"
   },
   "outputs": [],
   "source": [
    "a = torch.rand(10000, 10000)\n",
    "b = torch.rand(10000, 10000)\n",
    "a.matmul(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n54EwRJcgTJZ"
   },
   "source": [
    "### Move to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "MYylNgVDhAJ9",
    "outputId": "99c33b5f-37d5-41f2-913c-7dc16e5da906"
   },
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "5Rj0xFV2flUx",
    "outputId": "008e476b-7dac-4aa7-f300-40517bbc255f"
   },
   "outputs": [],
   "source": [
    "a = a.cuda()\n",
    "b = b.cuda()\n",
    "a.matmul(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hxMNFL7Egb5r",
    "outputId": "93af7aec-8c7e-4280-da7b-5d1a1728ee99"
   },
   "outputs": [],
   "source": [
    "features = torch.randn( (1,5))\n",
    "weights = torch.randn_like(features)\n",
    "bias = torch.randn( (1,1))\n",
    "\n",
    "print(torch.sum(features * weights + bias) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Pp_lP1qbiOQo",
    "outputId": "05a58eaf-03d3-48fb-b0d3-1dde55a2e863"
   },
   "outputs": [],
   "source": [
    "print(torch.mm(features, weights.view(5,1)) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gC-D7oybivYh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c675ME8YjH5-"
   },
   "source": [
    "### Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0sKvPBBAjJXj"
   },
   "outputs": [],
   "source": [
    "x = torch.autograd.Variable(torch.ones(2, 2), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "XqEDXzmejmEf",
    "outputId": "f062ed95-89db-4df8-95c5-120cbbb9f369"
   },
   "outputs": [],
   "source": [
    "y = x.mean()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3TqZl2kXjtC7",
    "outputId": "c9956dd0-0a2a-45c7-9164-ca35cf03f993"
   },
   "outputs": [],
   "source": [
    "print(y.backward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "zAVKRjzSjvv6",
    "outputId": "48480e67-e9ab-478b-f896-41e6bac6dcc0"
   },
   "outputs": [],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "bniVkOY5j0hB",
    "outputId": "d6c95ec1-86c2-4937-a845-89c4e930782f"
   },
   "outputs": [],
   "source": [
    "print(x.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "oKQPHRjRj7Pk",
    "outputId": "874ade40-3fc4-4cbb-986b-b37f8f4be291"
   },
   "outputs": [],
   "source": [
    "print(x.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "J4w64zCxj-Ht",
    "outputId": "8185f31c-358a-404f-ada7-f1b35c956021"
   },
   "outputs": [],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y3MwrFdHkdax"
   },
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "TvutX9fakbsj",
    "outputId": "fddbbb3b-b1b1-443c-edbd-0c69853c99f0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "df = pd.read_csv('/content/gdrive/My Drive/boston/train.csv', index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zBtE_64xkAJ9"
   },
   "outputs": [],
   "source": [
    "train_df = df.sample(frac=0.8,random_state=0)\n",
    "test_df = df.drop(train_df.index)\n",
    "\n",
    "columns = ['nox', 'rm', 'chas', 'dis', 'ptratio', 'lstat', 'rad']\n",
    "\n",
    "X_train = train_df[columns].values\n",
    "X_test = test_df[columns].values\n",
    "y_train = train_df[['medv']].values\n",
    "y_test = test_df[['medv']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7SeH5AYvpG4R"
   },
   "source": [
    "### Simple Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jZhtjFd4ooiC"
   },
   "outputs": [],
   "source": [
    "class SimpleModel():\n",
    "  def __init__(self, x, y, lr=0.001):\n",
    "    self.X = torch.autograd.Variable(torch.from_numpy(x).type(torch.FloatTensor))\n",
    "    self.y = torch.autograd.Variable(torch.from_numpy(y).type(torch.FloatTensor))\n",
    "    self.W = torch.autograd.Variable(torch.randn(x.shape[1], 1), requires_grad=True)\n",
    "    self.b = torch.autograd.Variable(torch.randn(1, 1), requires_grad=True)\n",
    "    self.alpha = lr\n",
    "    \n",
    "  def pred(self):\n",
    "    return torch.matmul(self.X, self.W) + self.b\n",
    "  \n",
    "  def loss_fn(self):\n",
    "    loss = (self.y - self.pred()).pow(2).sum()/self.X.shape[0]\n",
    "    for p in [self.W, self.b]:\n",
    "      if not p.grad is None:\n",
    "        p.grad.data.zero_()\n",
    "    loss.backward()\n",
    "    return loss.data.item()\n",
    "  \n",
    "  def optimize(self):\n",
    "    self.W.data -= self.alpha * self.W.grad.data\n",
    "    self.b.data -= self.alpha * self.b.grad.data\n",
    "    \n",
    "  def train(self, epochs=100):\n",
    "    for i in range(epochs):\n",
    "      l = self.loss_fn()\n",
    "      if i%10 == 0:\n",
    "        print('Step:{} -- Current Loss: {}'.format(i, l))\n",
    "      self.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T6P90baRoRKS"
   },
   "outputs": [],
   "source": [
    "model = SimpleModel(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "DDlKGqzxrZXc",
    "outputId": "df1e7e80-e8e8-4a9c-bd0f-35ad577d3bba"
   },
   "outputs": [],
   "source": [
    "model.train(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "afGhAYgx8_aM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AMMI_Day_7.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
